# ====================================================================
# RAG-Anything Configuration File
# ====================================================================
# Copy this file to .env and fill in your credentials
# 
# Supported providers:
# - Azure OpenAI (recommended)
# - OpenAI
# - Gemini (optional)
# ====================================================================

# ====================================================================
# PRIMARY LLM CONFIGURATION
# ====================================================================
# Choose your LLM provider: azure_openai, openai, or gemini
LLM_BINDING=azure_openai

# --------------------------------------------------------------------
# AZURE OPENAI CONFIGURATION (if LLM_BINDING=azure_openai)
# --------------------------------------------------------------------
# Your Azure OpenAI endpoint (format: https://YOUR-RESOURCE.openai.azure.com/)
LLM_BINDING_HOST=https://your-resource-name.openai.azure.com/

# Your Azure OpenAI API key
LLM_BINDING_API_KEY=your-azure-openai-api-key-here

# Azure API version (recommended: 2024-12-01-preview)
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# Your GPT-4 deployment name in Azure
AZURE_OPENAI_DEPLOYMENT=gpt-4

# --------------------------------------------------------------------
# STANDARD OPENAI CONFIGURATION (if LLM_BINDING=openai)
# --------------------------------------------------------------------
# Your OpenAI API key
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI base URL (optional, defaults to https://api.openai.com/v1)
OPENAI_BASE_URL=https://api.openai.com/v1

# OpenAI model selection
OPENAI_MODEL=gpt-4o-mini

# ====================================================================
# EMBEDDING CONFIGURATION
# ====================================================================
# Choose your embedding provider: azure_openai, openai
EMBEDDING_BINDING=azure_openai

# --------------------------------------------------------------------
# AZURE EMBEDDING CONFIGURATION (if EMBEDDING_BINDING=azure_openai)
# --------------------------------------------------------------------
# Azure endpoint for embeddings (can be same as LLM endpoint)
EMBEDDING_BINDING_HOST=https://your-resource-name.openai.azure.com/

# Azure API key for embeddings (can be same as LLM key)
EMBEDDING_BINDING_API_KEY=your-azure-openai-api-key-here

# Azure embedding deployment name
AZURE_EMBEDDING_DEPLOYMENT=text-embedding-3-large

# Azure embedding API version
AZURE_EMBEDDING_API_VERSION=2024-02-01

# Embedding dimensions (3072 for text-embedding-3-large, 1536 for ada-002)
EMBEDDING_DIM=3072

# --------------------------------------------------------------------
# STANDARD OPENAI EMBEDDING CONFIGURATION (if EMBEDDING_BINDING=openai)
# --------------------------------------------------------------------
# Uses OPENAI_API_KEY from above
# OpenAI embedding model
OPENAI_EMBEDDING_MODEL=text-embedding-3-large

# ====================================================================
# DOCUMENT PROCESSING CONFIGURATION
# ====================================================================
# Parser selection: mineru or docling
PARSER=mineru

# Parse method: auto, ocr, or txt
PARSE_METHOD=auto

# Output directory for parsed documents
OUTPUT_DIR=./output

# Enable multimodal processing
ENABLE_IMAGE_PROCESSING=true
ENABLE_TABLE_PROCESSING=true
ENABLE_EQUATION_PROCESSING=true

# Display content statistics after processing
DISPLAY_CONTENT_STATS=true

# ====================================================================
# BATCH PROCESSING CONFIGURATION
# ====================================================================
# Maximum concurrent files to process
MAX_CONCURRENT_FILES=4

# Supported file extensions
SUPPORTED_FILE_EXTENSIONS=.pdf,.jpg,.jpeg,.png,.bmp,.tiff,.tif,.gif,.webp,.doc,.docx,.ppt,.pptx,.xls,.xlsx,.txt,.md

# Process folders recursively
RECURSIVE_FOLDER_PROCESSING=true

# ====================================================================
# RAG CONFIGURATION
# ====================================================================
# Working directory for RAG storage
WORKING_DIR=./rag_storage

# Chunk size for document splitting
CHUNK_SIZE=1200
CHUNK_OVERLAP_SIZE=100

# Maximum tokens for various operations
MAX_TOKENS=32000
MAX_ENTITY_TOKENS=10000
MAX_RELATION_TOKENS=10000

# Query configuration
TOP_K=60
COSINE_THRESHOLD=0.2

# ====================================================================
# PERFORMANCE CONFIGURATION
# ====================================================================
# LLM temperature (0-1, lower = more deterministic)
TEMPERATURE=0.7

# Request timeout in seconds
TIMEOUT=240

# Enable caching for faster responses
ENABLE_LLM_CACHE=true
ENABLE_LLM_CACHE_FOR_EXTRACT=true

# Maximum concurrent async operations
MAX_ASYNC=4
MAX_PARALLEL_INSERT=2
EMBEDDING_FUNC_MAX_ASYNC=16
EMBEDDING_BATCH_NUM=32

# ====================================================================
# STORAGE CONFIGURATION
# ====================================================================
# Storage backends (default: JSON-based local storage)
LIGHTRAG_KV_STORAGE=JsonKVStorage
LIGHTRAG_DOC_STATUS_STORAGE=JsonDocStatusStorage
LIGHTRAG_GRAPH_STORAGE=NetworkXStorage
LIGHTRAG_VECTOR_STORAGE=NanoVectorDBStorage

# ====================================================================
# UI CONFIGURATION
# ====================================================================
# Server configuration for Gradio UI
HOST=0.0.0.0
PORT=7861
WEBUI_TITLE=RAG-Anything Multi-File Processor
WEBUI_DESCRIPTION=Process and query multiple documents with Azure OpenAI

# ====================================================================
# LOGGING CONFIGURATION
# ====================================================================
# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Verbose output
VERBOSE=False

# Log directory
LOG_DIR=./logs

# ====================================================================
# OPTIONAL: GEMINI CONFIGURATION
# ====================================================================
# Only needed if using Gemini as an alternative
GEMINI_API_KEY=AIza...your-gemini-key-here

# ====================================================================
# SETUP INSTRUCTIONS
# ====================================================================
# For Azure OpenAI:
# 1. Create an Azure OpenAI resource in Azure Portal
# 2. Deploy models:
#    - GPT-4 or GPT-4o for text generation
#    - text-embedding-3-large for embeddings
# 3. Copy API keys and endpoints from Azure Portal
# 4. Update the Azure sections above with your credentials
#
# For OpenAI:
# 1. Get API key from https://platform.openai.com/api-keys
# 2. Update OPENAI_API_KEY above
#
# For Gemini (optional):
# 1. Get API key from https://makersuite.google.com/app/apikey
# 2. Update GEMINI_API_KEY above